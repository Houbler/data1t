# Изучение Hive.
### Задание:
```
На очереди — Hive!

Первым делом нужно достать данные — заходим и грузим все, что есть из репозитория: [GitHub](https://github.com/sultanmurad/csv_files).

Эти файлы будут подвержены анализу, но в них кое-чего недостает — добавьте в каждый файл столбец с номером группы таким образом, чтобы файл был разделен на 10 групп. В файл customers.csv добавьте столбец с номером года, в который была совершена подписка (Subscription Date). Используйте средства python + pandas.

Загрузите полученные файлы на hdfs. 

Теперь ваша задача следующая: аналитики хотят сводную статистику на уровне каждой компании и на уровне каждого года получить целевую возрастную группу подписчиков — то есть, возрастную группу, представители которой чаще всего совершали подписку именно в текущий год на текущую компанию. 

Все операции необходимо выполнить в Hive. Работать с Hive можно через интерфейс HUE, если перейти в раздел «Query», или выбрав нужный пункт в разделе «Editor».

Таким образом вам нужно создать под каждый csv-файл отдельную таблицу. Для оптимизации используйте свои знания партиционирования и бакетирования. А затем на основе 3-х таблиц собрать витрину, которая решает поставленную задачу. В качестве результата предоставьте код SQL-запросов для создания исходных таблиц и создания итоговой витрины.
```

### Запуск
 - Скачиваем на компьютер файлы из репозитория: https://github.com/Houbler/data1t/tree/main/Chapter%204.5%20Hive
 - Открываем консоль, переходим в папку hadoop-hive-parquet
 - Вводим: docker-compose up

 Как только образ собран, а контейнер поднят — заходим по http://localhost:8888/hue и попадаем в HUE. Придумываем произвольную пару логина-пароля для будущей авторизации и приступаем к работе. 
 
 - Открываем cmd и вводим команды указанные здесь: [Команды для cmd](load_to_container.txt)
 - Запускаем [Питон скрипт](data_processing.py)
 - Затем вводим в Hive [SQL-скрипт](hive.sql)

 ### Результат
 Файл в формате [csv](data_mart.csv)
 таблица с выводом первых 20 строк в виде [скриншота](result.png) 